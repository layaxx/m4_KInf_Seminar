\section{Vergleich}
\label{sec:vergleich}


\paragraph{Verwendete Technologien}

Sowohl Genuine Semantic Publishing als auch SCICERO verwenden das vom World Wide Web Consortium (W3C) entwickelte Resource Description Framework (RDF) zur Modellierung der semantischen Daten.
Während Genuine Semantic Publishing auf die Beschreibung der Ergebnisse durch die Autoren setzt, gegebenenfalls auch ganz ohne einen begleitenden Text, verwendet SCICERO Natural Language Processing und Transformer-Modelle zur Extraktion semantischer Informationen aus bestehenden, textbasierten Publikationen.

Beide Ansätze verwenden Ontologien, um die extrahierten Informationen zu strukturieren.
SCICERO verwendet dabei in der Originalform eine explizit für Informatik ausgelegte Ontologie.
Wie im vorangegangenen Kapitel beschrieben, ist aber mit gewissen Anpassungen auch die Verwendung einer anderen Ontologie möglich, beispielsweise für einen enger begrenzten Teilbereich der Informatik oder auch für komplett andere Forschungsfelder.
Genuine Semantic Publishing ist währenddessen größtenteils agnostisch gegenüber der Wahl konkreter Technologien, solange diese dazu beiträgt, die fünf Forderungen zu erfüllen.
Entsprechend empfehlen die Autoren keine spezifische Ontologie, nennen aber Beispiele wie CiTO (Citation Typing Ontology, \cite{cito}) und SKOS (Simple Knowledge Organisation, \cite{skos}).

\paragraph{Nachvollziehbarkeit}

Beide Ansätze enthalten Herkunftsinformationen (im Original: \textit{provenance}) über die Forschungsergebnisse.
Bei Genuine Semantic Publishing beziehen sich diese Informationen auf die Autoren selbst, die die semantischen Daten erstellt haben.
Dadurch soll ein Anreiz geschaffen werden, die Daten korrekt und vollständig zu erstellen \cite{kuhn2017genuine}.
Außerdem stellt das sicher, dass die Intention der Autoren korrekt wiedergegeben wird, da diese die Daten direkt anlegen.
Dadurch entfällt der Umweg über potentiell weniger eindeutigen Text in natürlicher Sprache, der anfälliger für Missverständnisse oder Unklarheiten ist.

Bei SCICERO sind neben den Artikeln, aus denen die Informationen extrahiert wurden, auch die Modelle und Methoden, die zur Extraktion verwendet wurden, Teil der Herkunftsinformationen.
Wie bei allen KI-basierten Ansätzen kann es aber natürlich auch hier zu Fehlern oder Halluzinationen kommen.
Diese können an mehreren Stellen im Prozess auftreten.
Dass in der Extraktionsstufe beispielsweise Entitäten oder Relationen erkannt werden, die so gar nicht im Text enthalten sind, ist ein ganz natürlicher Aspekt von SCICERO, weswegen ja auch am Schluss noch eine Validierung erfolgt, in der inkorrekte Daten erkannt und entfernt werden sollen.
Aber auch diese Validierung ist natürlich nicht perfekt, und es kann auch hier zu Fehlern kommen, indem entweder korrekte Daten verworfen oder inkorrekte aufgenommen werden.
Genauso können in der Harmonisierung der Daten Fehler auftreten, wenn beispielsweise zwei Entitäten, die eigentlich das gleiche Konzept beschreiben, nicht zusammengeführt werden oder zwei unterschiedliche Entitäten irrtümlich zusammengeführt werden.
In der Evaluation von SCICERO finden die Autoren zwar heraus, dass bessere Werte als mit anderen Ansätzen erreicht werden, aber auch hier gibt es mit Precision-Raten von ca. 75\% noch deutliches Verbesserungspotential.


\paragraph{Realisierbarkeit}

Eines der Hauptargumente, die bei dem beschriebenen Anwendungsszenario gegen Genuine Semantic Publishing sprechen, ist die Realisierbarkeit.
Während SCICERO jederzeit schon eingesetzt werden könnte, um Wissensgraphen für Forschungsfelder zu erstellen \textemdash wie die Autoren ja auch mit ihrem Wissensgraphen zum Feld der Informatik zeigen \cite{cskg} \textemdash ist Genuine Semantic Publishing erst einmal eine Zukunftsvision.
Neben dem Aufwand, den Autoren zukünftig in die Formalisierung ihrer Ergebnisse stecken müssten, erfordert dieser Ansatz in erster Linie einen Paradigmenwechsel im gesamten Publikationsprozess.
Um das zu schaffen, müsste also eine heterogene Menge an Beteiligten \textemdash allen voran natürlich Wissenschaftler und Verleger \textemdash sich darauf einigen, diesen Weg zu beschreiten.
Hilfreich wäre es sicherlich, wenn sich hierfür eine Standard-Ontologie etablieren würde, die von allen Beteiligten genutzt werden könnte.
Außerdem wäre auch eine Infrastruktur an Tools und Services notwendig, die die Autoren bei der Erstellung der semantischen Daten unterstützen.
Auf Nanopublikationen setzende Experimente konnten zwar schon die prinzipielle Bereitschaft von Autoren zeigen, sich auf solche derartige Neuerungen einzulassen \cite{nanopub-experiment}, ob das aber auch für eine flächendeckende Umstellung reicht, ist angesichts des begrenzten Umfangs der Studie weiterhin fraglich.

Auch dann bleibt noch das Problem der bereits existierenden Publikationen, die nicht für maschinelle Verarbeitung ausgelegt sind.
Für diese müsste dann eine zusätzliche Lösung, etwa eine rückwirkende Anreicherung relevanter Literatur mit semantischen Daten oder Methoden wie SCICERO, gefunden werden.

\paragraph{Konsistenz}

Ein weiterer potentieller Nachteil von Genuine Semantic Publishing ist die Konsistenz der erstellten Daten.
Da die Autoren selbst für die Erstellung der semantischen Daten verantwortlich sind, könnte es zu Inkonsistenzen kommen, wenn beispielsweise verschiedene Autoren unterschiedliche Ontologien verwenden oder die gleichen Konzepte unterschiedlich benennen.
Hier wären entweder standardisierte Ontologien notwendig oder eine (teil-)automatisierte Harmonisierung der Daten, wie sie beispielsweise SCICERO durchführt.

Da bei SCICERO hingegen dasselbe System für die Extraktion und Harmonisierung der Daten aller Publikationen verwendet wird, ist die Konsistenz der Daten hier gewährleistet.
Andererseits sind \textemdash gerade durch den Einsatz von Transformer-Modellen \textemdash auch Fehler in der Extraktion möglich, die dann in allen extrahierten Daten auftreten.
Außerdem ist dadurch auch die benötigte Rechenleistung ein Vielfaches höher als bei manuellen Ansätzen.


\paragraph{Weitere Herausforderungen}

SCICERO ist darauf ausgelegt, sehr große Mengen an Texten zu verarbeiten.
Ob es bei geringeren Datenmengen, wie sie beispielsweise in einem spezifischen Forschungsfeld auftreten, zu Einschränkungen \textemdash etwa in der Genauigkeit der Validierung \textemdash kommt, ist nicht klar.

Bei beiden Ansätzen besteht die Gefahr, dass die semantischen Daten nicht alle für das Living Literature Review relevanten Daten enthalten.
Da sich aber sowohl SCICERO als auch Genuine Semantic Publishing lediglich auf die Erstellung von Wissensgraphen konzentrieren, die dann als Grundlage für die Literaturübersicht dienen, ist die weitere Verarbeitung zur fertigen Übersicht aus dem Graphen für diese Arbeit nicht relevant.