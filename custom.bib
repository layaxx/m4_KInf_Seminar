@article{kuhn2017genuine,
  title     = {Genuine semantic publishing},
  author    = {Kuhn, Tobias and Dumontier, Michel},
  journal   = {Data Science},
  volume    = {1},
  number    = {1-2},
  pages     = {139--154},
  year      = {2017},
  publisher = {SAGE Publications Sage UK: London, England}
}
@article{DESSI2022109945,
  title    = {SCICERO: A deep learning and NLP approach for generating scientific knowledge graphs in the computer science domain},
  journal  = {Knowledge-Based Systems},
  volume   = {258},
  pages    = {109945},
  year     = {2022},
  issn     = {0950-7051},
  doi      = {https://doi.org/10.1016/j.knosys.2022.109945},
  url      = {https://www.sciencedirect.com/science/article/pii/S0950705122010383},
  author   = {Danilo Dess√≠ and Francesco Osborne and Diego {Reforgiato Recupero} and Davide Buscaldi and Enrico Motta},
  keywords = {Knowledge graph, Scholarly domain, Scientific facts, Artificial intelligence},
  abstract = {Science communication has a number of bottlenecks that include the rising number of published research papers and its non-machine-accessible and document-based paradigm, which makes the exploration, reading, and reuse of research outcomes rather inefficient. Recently, Knowledge Graphs (KG), i.e., semantic interlinked networks of entities, have been proposed as a new core technology to describe and curate scholarly information with the goal to make it machine readable and understandable. However, the main drawback of the use of such a technology is that researchers are asked to manually annotate their research papers and add their contributions within the KGs. To address this problem, in this paper we propose SCICERO, a novel KG generation approach that takes in input text from research articles and generates a KG of research entities. SCICERO uses Natural Language Processing techniques to parse the content of scientific papers to discover entities and relationships, exploits state-of-the-art Deep Learning Transformer models to make sense and validate extracted information, and uses Semantic Web best practices to formally represent the extracted entities and relationships, making the written content of research papers machine-actionable. SCICERO has been tested on a dataset of 6.7M papers about Computer Science generating a KG of about 10M entities. It has been evaluated on a manually generated gold standard of 3,600 triples that cover three Computer Science subdomains (Information Retrieval, Natural Language Processing, and Machine Learning) obtaining remarkable results.}
}
@inproceedings{wadden-etal-2019-entity,
  title     = {Entity, Relation, and Event Extraction with Contextualized Span Representations},
  author    = {Wadden, David  and
               Wennberg, Ulme  and
               Luan, Yi  and
               Hajishirzi, Hannaneh},
  editor    = {Inui, Kentaro  and
               Jiang, Jing  and
               Ng, Vincent  and
               Wan, Xiaojun},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  month     = nov,
  year      = {2019},
  address   = {Hong Kong, China},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/D19-1585/},
  doi       = {10.18653/v1/D19-1585},
  pages     = {5784--5789},
  abstract  = {We examine the capabilities of a unified, multi-task framework for three information extraction tasks: named entity recognition, relation extraction, and event extraction. Our framework (called DyGIE++) accomplishes all tasks by enumerating, refining, and scoring text spans designed to capture local (within-sentence) and global (cross-sentence) context. Our framework achieves state-of-the-art results across all tasks, on four datasets from a variety of domains. We perform experiments comparing different techniques to construct span representations. Contextualized embeddings like BERT perform well at capturing relationships among entities in the same or adjacent sentences, while dynamic span graph updates model long-range cross-sentence relationships. For instance, propagating span representations via predicted coreference links can enable the model to disambiguate challenging entity mentions. Our code is publicly available at \url{https://github.com/dwadden/dygiepp} and can be easily adapted for new tasks or datasets.}
}
@inbook{Ceri2013,
  author    = {Ceri, Stefano
               and Bozzon, Alessandro
               and Brambilla, Marco
               and Della Valle, Emanuele
               and Fraternali, Piero
               and Quarteroni, Silvia},
  title     = {The Information Retrieval Process},
  booktitle = {Web Information Retrieval},
  year      = {2013},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {13--26},
  abstract  = {What does an information retrieval system look like from a bird's eye perspective? How can a set of documents be processed by a system to make sense out of their content and find answers to user queries? In this chapter, we will start answering these questions by providing an overview of the information retrieval process. As the search for text is the most widespread information retrieval application, we devote particular emphasis to textual retrieval. The fundamental phases of document processing are illustrated along with the principles and data structures supporting indexing.},
  isbn      = {978-3-642-39314-3},
  doi       = {10.1007/978-3-642-39314-3_2},
  url       = {https://doi.org/10.1007/978-3-642-39314-3_2}
}
@inproceedings{cskg,
  booktitle = {ISWC 2022: 21st International Semantic Web Conference},
  month     = {October},
  journal   = {The Semantic Web - ISWC 2022. Lecture Notes in Computer Science},
  publisher = {Springer, Cham},
  pages     = {678--696},
  title     = {CS-KG: A Large-Scale Knowledge Graph of Research Entities and Claims in Computer Science},
  year      = {2022},
  volume    = {13489},
  keywords  = {Knowledge Graph; Scholarly Data; Information Extraction; Natural Language Processing; Semantic Web; Artificial Intelligence},
  abstract  = {In recent years, we saw the emergence of several approaches for producing machine-readable, semantically rich, interlinked descriptions of the content of research publications, typically encoded as knowledge graphs. A common limitation of these solutions is that they address a low number of articles, either because they rely on human experts to summarize information from the literature or because they focus on specific research areas. In this paper, we introduce the Computer Science Knowledge Graph (CS-KG), a large-scale knowledge graph composed by over 350M RDF triples describing 41M statements from 6.7M articles about 10M entities linked by 179 semantic relations. It was automatically generated and will be periodically updated by applying an information extraction pipeline on a large repository of research papers. CS-KG is much larger than all comparable solutions and offers a very comprehensive representation of tasks, methods, materials, and metrics in Computer Science. It can support a variety of intelligent services, such as advanced literature search, document classification, article recommendation, trend forecasting, hypothesis generation, and many others. CS-KG was evaluated against a benchmark of manually annotated statements, yielding excellent results.},
  author    = {Dess{\'i}, Danilo and Osborne, Francesco and Reforgiato Recupero, Diego and Buscaldi, Davide and Motta, Enrico},
  isbn      = {978-3-031-19432-0},
  url       = {https://oro.open.ac.uk/85306/}
}
@inproceedings{aikg,
  author    = {Dess{\`i}, Danilo
               and Osborne, Francesco
               and Reforgiato Recupero, Diego
               and Buscaldi, Davide
               and Motta, Enrico
               and Sack, Harald},
  editor    = {Pan, Jeff Z.
               and Tamma, Valentina
               and d'Amato, Claudia
               and Janowicz, Krzysztof
               and Fu, Bo
               and Polleres, Axel
               and Seneviratne, Oshani
               and Kagal, Lalana},
  title     = {AI-KG: An Automatically Generated Knowledge Graph of Artificial Intelligence},
  booktitle = {The Semantic Web -- ISWC 2020},
  year      = {2020},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {127--143},
  abstract  = {Scientific knowledge has been traditionally disseminated and preserved through research articles published in journals, conference proceedings, and online archives. However, this article-centric paradigm has been often criticized for not allowing to automatically process, categorize, and reason on this knowledge. An alternative vision is to generate a semantically rich and interlinked description of the content of research publications. In this paper, we present the Artificial Intelligence Knowledge Graph (AI-KG), a large-scale automatically generated knowledge graph that describes 820K research entities. AI-KG includes about 14M RDF triples and 1.2M reified statements extracted from 333K research publications in the field of AI, and describes 5 types of entities (tasks, methods, metrics, materials, others) linked by 27 relations. AI-KG has been designed to support a variety of intelligent services for analyzing and making sense of research dynamics, supporting researchers in their daily job, and helping to inform decision-making in funding bodies and research policymakers. AI-KG has been generated by applying an automatic pipeline that extracts entities and relationships using three tools: DyGIE++, Stanford CoreNLP, and the CSO Classifier. It then integrates and filters the resulting triples using a combination of deep learning and semantic technologies in order to produce a high-quality knowledge graph. This pipeline was evaluated on a manually crafted gold standard, yielding competitive results. AI-KG is available under CC BY 4.0 and can be downloaded as a dump or queried via a SPARQL endpoint.},
  isbn      = {978-3-030-62466-8}
}
@inproceedings{citation-recommendation,
  author    = {Brack, Arthur
               and Hoppe, Anett
               and Ewerth, Ralph},
  editor    = {Berget, Gerd
               and Hall, Mark Michael
               and Brenn, Daniel
               and Kumpulainen, Sanna},
  title     = {Citation Recommendation for Research Papers via Knowledge Graphs},
  booktitle = {Linking Theory and Practice of Digital Libraries},
  year      = {2021},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {165--174},
  abstract  = {Citation recommendation for research papers is a valuable task that can help researchers improve the quality of their work by suggesting relevant related work. Current approaches for this task rely primarily on the text of the papers and the citation network. In this paper, we propose to exploit an additional source of information, namely research knowledge graphs (KGs) that interlink research papers based on mentioned scientific concepts. Our experimental results demonstrate that the combination of information from research KGs with existing state-of-the-art approaches is beneficial. Experimental results are presented for the STM-KG (STM: Science, Technology, Medicine), which is an automatically populated knowledge graph based on the scientific concepts extracted from papers of ten domains. The proposed approach outperforms the state of the art with a mean average precision of 20.6{\%} (+0.8) for the top-50 retrieved results.},
  isbn      = {978-3-030-86324-1}
}

@article{scientific-growth,
  author = {Kang, Huquan and Fu, Luoyi and Funk, Russell and Wang, Xinbing and Ding, Jiaxin and Liang, Shiyu and Wang, Jianghao and Zhou, Lei and Zhou, Chenghu},
  year   = {2024},
  month  = {09},
  pages  = {},
  title  = {Scientific and technological knowledge grows linearly over time},
  doi    = {10.48550/arXiv.2409.08349}
}

@article{elliott2017living,
  title     = {Living systematic review: 1. Introduction‚Äîthe why, what, when, and how},
  author    = {Elliott, Julian H and Synnot, Anneliese and Turner, Tari and Simmonds, Mark and Akl, Elie A and McDonald, Steve and Salanti, Georgia and Meerpohl, Joerg and MacLehose, Harriet and Hilton, John and others},
  journal   = {Journal of clinical epidemiology},
  volume    = {91},
  pages     = {23--30},
  year      = {2017},
  publisher = {Elsevier}
}
@misc{cochrane,
  title  = {Guidance for the production and publication of Cochrane living systematic reviews: Cochrane Reviews in living mode},
  author = {Cochrane},
  note   = {\url{https://community.cochrane.org/sites/default/files/uploads/inline-files/Transform/201912_LSR_Revised_Guidance.pdf}},
  note   = {Accessed: 8-1-2025}
}
@inproceedings{living-lit-review,
  author    = {Wijkstra, Michel and Lek, Timo and Kuhn, Tobias and Welbers, Kasper and Steijaert, Mickey},
  title     = {Living Literature Reviews},
  year      = {2021},
  isbn      = {9781450384575},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3460210.3493567},
  doi       = {10.1145/3460210.3493567},
  abstract  = {Literature reviews have long played a fundamental role in synthesizing the current state of a research field. However, in recent years, certain fields have evolved at such a rapid rate that literature reviews quickly lose their relevance as new work is published that renders them outdated. We should therefore rethink how to structure and publish such literature reviews with their highly valuable synthesized content. Here, we aim to determine if existing Linked Data technologies can be harnessed to prolong the relevance of literature reviews and whether researchers are comfortable with working with such a solution. We present here our approach of "living literature reviews'' where the core information is represented as Linked Data which can be amended with new findings after the publication of the literature review. We present a prototype implementation, which we use for a case study where we expose potential users to a concrete literature review modeled with our approach. We observe that our model is technically feasible and is received well by researchers, with our "living'' versions scoring higher than their traditional counterparts in our user study. In conclusion, we find that there are strong benefits to using a Linked Data solution to extend the effective lifetime of a literature review.},
  booktitle = {Proceedings of the 11th Knowledge Capture Conference},
  pages     = {241‚Äì248},
  numpages  = {8},
  keywords  = {literature reviews, nanopublications, scientific communication, semantic publishing},
  location  = {Virtual Event, USA},
  series    = {K-CAP '21}
}
@article{nanopubs,
  author   = {Paul Groth and Andrew Gibson and Jan Velterop},
  title    = {The anatomy of a nanopublication},
  journal  = {Information Services and Use},
  volume   = {30},
  number   = {1-2},
  pages    = {51-56},
  year     = {2010},
  doi      = {10.3233/ISU-2010-0613},
  url      = {https://doi.org/10.3233/ISU-2010-0613},
  eprint   = {https://doi.org/10.3233/ISU-2010-0613},
  abstract = { As the amount of scholarly communication increases, it is increasingly difficult for specific core scientific statements to be found, connected and curated. Additionally, the redundancy of these statements in multiple fora makes it difficult to determine attribution, quality and provenance. To tackle these challenges, the Concept Web Alliance has promoted the notion of nanopublications (core scientific statements with associated context). In this document, we present a model of nanopublications along with a Named Graph/RDF serialization of the model. Importantly, the serialization is defined completely using already existing community-developed technologies. Finally, we discuss the importance of aggregating nanopublications and the role that the Concept Wiki plays in facilitating it. }
}

Ôªø@article{cito,
  author   = {Shotton, David},
  title    = {CiTO, the Citation Typing Ontology},
  journal  = {Journal of Biomedical Semantics},
  year     = {2010},
  month    = {Jun},
  day      = {22},
  volume   = {1},
  number   = {1},
  pages    = {S6},
  abstract = {CiTO, the Citation Typing Ontology, is an ontology for describing the nature of reference citations in scientific research articles and other scholarly works, both to other such publications and also to Web information resources, and for publishing these descriptions on the Semantic Web. Citation are described in terms of the factual and rhetorical relationships between citing publication and cited publication, the in-text and global citation frequencies of each cited work, and the nature of the cited work itself, including its publication and peer review status. This paper describes CiTO and illustrates its usefulness both for the annotation of bibliographic reference lists and for the visualization of citation networks. The latest version of CiTO, which this paper describes, is CiTO Version 1.6, published on 19 March 2010. CiTO is written in the Web Ontology Language OWL, uses the namespace http://purl.org/net/cito/, and is available from http://purl.org/net/cito/. This site uses content negotiation to deliver to the user an OWLDoc Web version of the ontology if accessed via a Web browser, or the OWL ontology itself if accessed from an ontology management tool such as Prot{\'e}g{\'e} 4 (http://protege.stanford.edu/). Collaborative work is currently under way to harmonize CiTO with other ontologies describing bibliographies and the rhetorical structure of scientific discourse.},
  issn     = {2041-1480},
  doi      = {10.1186/2041-1480-1-S1-S6},
  url      = {https://doi.org/10.1186/2041-1480-1-S1-S6}
}
@article{skos,
  author  = {Miles, Alistair and Matthews, Brian and Wilson, Michael and Brickley, Dan},
  journal = {International Conference on Dublin Core and Metadata Applications},
  doi     = {10.23106/dcmi.952107985},
  year    = {2005},
  month   = {sep 12},
  title   = {SKOS {Core}: Simple knowledge organisation for the {Web}},
  volume  = {2005}
}
@inproceedings{linked-lit-review,
  author    = {Jiomekong, Azanzi and Auer, S\"{o}ren and Oelen, Allard},
  title     = {Linked Open Literature Review using the Neuro-symbolic Open Research Knowledge Graph},
  year      = {2024},
  isbn      = {9798400701726},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3589335.3651238},
  doi       = {10.1145/3589335.3651238},
  abstract  = {The way scholarly knowledge and in particular literature reviews are communicated today rather resembles static, unstructured, pseudo-digitized articles, which are hardly processable by machines and AI. This demo showcases a novel way to create and publish scholarly literature reviews, also called semantic reviews. The neuro-symbolic approach consists of extracting key insights from scientific papers leveraging neural models and organizing them using a symbolic scholarly knowledge graph. The food information engineering review case study will allow participants to see how this approach is implemented using the Open Research Knowledge Graph (ORKG). The real-time demo will allow participants to play with the ORKG and create their own living, semantic review.},
  booktitle = {Companion Proceedings of the ACM Web Conference 2024},
  pages     = {1015‚Äì1018},
  numpages  = {4},
  keywords  = {fair principle, linked open data, literature review, neuro-symbolic ai, scholarly knowledge graph},
  location  = {Singapore, Singapore},
  series    = {WWW '24}
}
@inproceedings{Tsaneva2024EnhancingSK,
  title     = {Enhancing Scientific Knowledge Graph Generation Pipelines with LLMs and Human-in-the-Loop},
  author    = {Stefani Tsaneva and Danilo Dess{\'i} and Francesco Osborne and Marta Sabou},
  booktitle = {Sci-K@ISWC},
  year      = {2024},
  url       = {https://api.semanticscholar.org/CorpusID:273340410}
}

